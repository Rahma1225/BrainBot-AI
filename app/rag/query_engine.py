from typing import List, Union, Tuple
from app.services.embedding import embed_texts
from app.services.storage import retrieve_similar_chunks
from app.services.ollama_service import ask_ollama


def answer_with_rag(question: str, similarity_threshold: float = 0.7, top_n: int = 5) -> str:
    # 1. GÃ©nÃ©rer l'embedding de la question
    query_embedding = embed_texts([question])[0]

    # 2. RÃ©cupÃ©rer les chunks similaires depuis ChromaDB
    retrieved = retrieve_similar_chunks(query_embedding, top_n=top_n)

    # 3. Filtrer les chunks si des scores de similaritÃ© sont prÃ©sents
    if retrieved and isinstance(retrieved[0], tuple):
        filtered_chunks: List[str] = [
            chunk for chunk, score in retrieved if score >= similarity_threshold
        ]
    else:
        filtered_chunks = [chunk for chunk in retrieved]  # type: ignore

    if not filtered_chunks:
        return "Aucune information pertinente trouvÃ©e pour rÃ©pondre Ã  la question."

    # 4. Construire le prompt en franÃ§ais
    context = "\n".join(filtered_chunks)
    prompt = (
    "Tu es un assistant intelligent spÃ©cialisÃ© dans la lecture et lâ€™analyse de documents techniques et fonctionnels (guides, procÃ©dures, manuels dâ€™implÃ©mentation, etc.).\n"
    "Tu dois rÃ©pondre Ã  la question ci-dessous UNIQUEMENT en te basant sur le CONTEXTE fourni.\n"
    "Ta rÃ©ponse doit Ãªtre rÃ©digÃ©e en franÃ§ais, claire, structurÃ©e et toujours fidÃ¨le au contenu du contexte.\n\n"
    "ğŸ“Œ RÃ¨gles Ã  respecter :\n"
    "1. Si la question contient un **code, Ã©cran, identifiant ou rÃ©fÃ©rence (ex : IN201000)** â†’ indique Ã  quoi cela correspond, avec citation ou extrait du contexte si possible.\n"
    "2. Si la question concerne une **liste dâ€™Ã©tapes, une procÃ©dure ou un plan structurÃ©** â†’ prÃ©sente la rÃ©ponse sous forme de **liste numÃ©rotÃ©e**, avec des **puces pour les sous-Ã©lÃ©ments**.\n"
    "3. Si le contexte suit une **structure ou un sommaire clair** (ex : PrÃ©paration, Configuration, Initialisation...) â†’ respecte **lâ€™ordre exact** et **les titres** tels quâ€™ils apparaissent dans le texte.\n"
    "4. Si **aucune rÃ©ponse claire ne peut Ãªtre dÃ©duite**, Ã©cris simplement : \"ğŸ“Œ Le contexte ne fournit pas cette information.\"\n"
    "5. Ne reformule pas les titres du contexte. Utilise-les tels quels si prÃ©sents.\n"
    "6. Sois concis mais complet : ta rÃ©ponse doit reflÃ©ter **tout ce qui est pertinent dans le contexte**.\n\n"
    f"ğŸ“˜ CONTEXTE :\n{context}\n\n"
    f"â“ QUESTION : {question}"
)



    # 5. Envoyer le prompt au modÃ¨le
    answer = ask_ollama(prompt)

    # 6. VÃ©rification facultative de la pertinence
    if any(chunk in answer for chunk in filtered_chunks):
        return answer
    else:
        return answer + "\n\n(Note : La rÃ©ponse pourrait ne pas Ãªtre entiÃ¨rement appuyÃ©e par le contexte fourni.)"
